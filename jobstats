#!/usr/bin/env perl

# Discover Uppmax jobstats files, make preliminary analysis of resource usage,
# and invoke plot_jobstats for further analysis and plot production.
#
# Latest is available at https://github.com/douglasgscofield/uppmax
#
# DONE: (from lka) help information about flag:number:number values
# DONE: (from lka) verbose flag to be wordy about flag output?
# DONE: (from lka) get current cluster from $SNIC_RESOURCE
# DONE: (from lka) memory flag only included if already a cores issue
# DONE: (from lka) problem with plots from 100-node tintin job, and with 10-node tintin job
# DONE: include more about user, jobstate in plot and table
# TODO: add -A to call finishedjobinfo with project name
# TODO: add usage of Martin's sqlite3 db if it is available (i.e. if we are on milou-b)
# TODO: is there another, deeper, location for jobstats files we can check?

my $version = "2015-02-24";

use strict;
use warnings;
# use diagnostics;

use Getopt::Long qw(:config no_ignore_case);
use File::Basename;
use Cwd 'abs_path';

my $CWD = dirname(abs_path($0));
my $NAME = basename($0);

# valid values for --source
# "fji" for finishedjobinfo, "db" for Martin's database
my %source_values = ( fji => "fji", finishedjobinfo => "fji", db => "db" );
# flag passed to $o_plot_jobstats for each source type
my %source_R_flags = ( fji => "--fji", db => "--db" );

# options and user values
my $o_cluster = $ENV{'SNIC_RESOURCE'} ? $ENV{'SNIC_RESOURCE'} : 'milou';  # -M
my $o_source          = "fji";
my $o_plot            = 0;  # -p
my $o_memory          = 0;  # -m
my $o_project;              # -A
my $o_nodes;                # -n
my $o_stdin           = 0;  # -- for finishedjobinfo info on stdin
my $o_header          = 0;  # -d
my $o_verbose         = 0;  # -v
my $o_quiet           = 0;  # -q
my $o_finishedjobinfo = "/sw/uppmax/bin/finishedjobinfo"; # -f
my $o_plot_jobstats   = "$CWD/plot_jobstats"; # -r
my $o_prefix          = "/sw/share/slurm"; # -x
my $o_hardprefix      = ""; # -X
my $o_help;                 # -h
my @nodes;    # after unpacking finishedjobinfo or -n
my @jobs;     # user-specified jobids

my $usage = "
$NAME  -p [options] [ -M cluster ] [ jobid [ jobid ... ] | -A project | - ]

Discover jobstats for the specified job(s) on the specified cluster.  Cluster
defaults to the value of \$SNIC_RESOURCE ('$ENV{'SNIC_RESOURCE'}' on the current system) if
not specified.

With the -p/--plot option, a plot is produced for each jobid.  Plots contain
one panel per booked node showing CPU and memory usage, and include lines
indicating the usage flags.  Plots are saved to the current directory with the
name

    cluster-jobid-project-user.png

Note that not all jobs will produce jobstats files, particularly if the job was
cancelled or ran for less than 5 minutes.  Also, if a job booked nodes
inefficiently by not using nodes it asked for, jobstats files will not be
available for the booked but unused nodes.

JOBSTATS DISCOVERY
------------------

There are four basic modes for discovery, depending on what the user provides
on the command line: (1) discovery by job number; (2) discovery by node and job
number; (3) discovery by project; or (4) discovery via information provided on
'stdin'.  In of the example command lines below, the -p/--plot option requests
that plots of job resource usage are created.

Mode 1:  $NAME -p jobid1 jobid2 jobid3
-------
Job numbers valid on the cluster.  finishedjobinfo is used to determine further
information for each job.  This can be rather slow, so if multiple queries are
expected it would be quicker to run finishedjobinfo yourself separately, see
Mode 4 below.

Mode 2:  $NAME -p -n m15,m16 jobid
-------
finishedjobinfo is *not* called and Uppmax's stored job statistics files are
discovered directly.  If you know which node(s) your job ran on or which nodes
you are interested in, this will be much faster than Mode 1.

Mode 3:  $NAME -p -A project
-------
When providing a project name that is valid for the cluster, finishedjobinfo is
used to determine further information on jobs run within the project.  As for
Mode 1, this can be rather slow.  Furthermore only finishedjobinfo defaults for
time span etc. are used for job discovery.  If multiple queries are expected or
additional finishedjobinfo options are desired, see Mode 4 below.

Mode 4:  finishedjobinfo -q project | $NAME - -p
-------
Accept input on stdin formatted like finishedjobinfo output.  The long form of
this option is '--stdin'.  This mode can be especially useful if multiple
queries of the same job information are expected.  In this case, save the
output of a single comprehensive finishedjobinfo query, and extract the parts
of interest and present them to this script on stdin.  For example, to produce
analyses of all completed jobs in a project during the current calendar year,
and produce separate tarballs analysing all jobs and providing jobstats plots
for each user during this same period:

     finishedjobinfo -q -y project > proj-year.txt
     grep 'jobstat=COMPLETED' proj-year.txt | $NAME - > all-completed-jobs.txt
     grep 'username=user1' proj-year.txt | $NAME - -p > user1-jobs.txt
     tar czf user1-jobs.tar.gz user1-jobs.txt *-project-user1.png
     grep 'username=user2' proj-year.txt | $NAME - -p > user2-jobs.txt
     tar czf user2-jobs.tar.gz user2-jobs.txt *-project-user2.png
     ...

COMMAND-LINE OPTIONS
--------------------

    -M cluster         Cluster on which jobs were run [default current cluster]

    -A project         Project valid on the cluster.  finishedjobinfo is used to
                       discover jobs for the project.  See further comments 
                       under 'Mode 3' above.

    -n node[,node...]  Cluster node(s) on which the job was run.  If specified,
                       then the finishedjobinfo script is not run and discovery
                       is restricted to only the specified nodes.  Nodes can be 
                       specified as a comma-separated list of complete node 
                       names, or using the finishedjobinfo syntax:
                             m78,m90,m91,m92,m100  or  m[78,90-92,100]
                       Nonsensical results will occur if the syntaxes are mixed.

    - | --stdin        Accept input on stdin formatted like finishedjobinfo 
                       output.  The short form of this option is a single dash 
                       '-'.
                       
    -m | --memory      Always include memory usage flags in output.  Default 
                       behaviour is to include memory usage flags only if CPU 
                       usage flags are also present.

    -s | --source  fji | db
                       Source of the input data.  Default is '$o_source', the
                       finishedjobinfo script. 'db' may be used to access a more
                       rapid but less comprehensive database of job information.
                       This may also be used with the - flag when sending job
                       information via stdin.  '-s db' is currently unsupported.

    -v | --verbose     Be wordy when describing flag values.

    -p | --plot        Produce CPU and memory usage plot for each jobid

    -q | --quiet       Do not produce table output

    -d                 Produce a header for table output

    -h | --help | -?   Produce detailed help information


The following command-line options are generally only useful for Uppmax staff.

    -x directory       Directory prefix to use for jobstats files.  Default is
                       '$o_prefix', and directory structure is 

                       <prefix>/<cluster>/uppmax_jobstats/<node>/<jobid>

    -X directory       Hard directory prefix to use for jobstats files.  
                       Jobstats files are assumed available directly: 
                           '<hard-prefix>/<jobid>'
    -f file            finishedjobinfo script [default is '$o_finishedjobinfo']
    -r file            plot_jobstats script [default is '$o_plot_jobstats']

";

my $detailed_usage = "FURTHER DETAILS
---------------

This script produces two types of output.  If the -p/--plot command line option
is provided, a plot is created of core and memory usage across the life of the
job.  The name of the file produced has the format:

    cluster-jobid-project-user.png

Unless the -q/--quiet option is provided, a table is also produces containing
lines with the following tab-separated fields:

  jobid cluster jobstate user project endtime runtime flags booked cores node[,node...] jobstats[,jobstats...] 

Field contents:

  jobid    : Job ID
  cluster  : Cluster on which the job was run
  jobstate : End status of the job: COMPLETED, FAILED, TIMEOUT, CANCELLED
  user     : Username that submitted the job
  project  : Project account under which the job was run
  endtime  : End time of the job (with -n, this is '.')
  runtime  : Runtime of the job (with -n, this is '.')
  flags    : Flags indicating various types of resource underutilizations
  booked   : Number of booked cores (with -n, this is '.')
  cores    : Number of cores represented in the discovered jobstats files.
  node     : Node(s) booked for the job, expanded into individual node names,
             separated by commas ','; if no nodes were found, this is '.'.  
             The nodes for which jobstats files are available are listed first.
  jobstats : jobstats files for the nodes, in the same order the nodes are 
             listed, separated by commas ','; if no jobstats files, this is '.'

FLAGS
-----

An important part of $NAME output are usage flags.  These provide indications
that booked resources -- processor cores or memory -- might have been
underused.

In both plot and table output, flags are a comma-separated list of cautions
regarding core and/or memory underutilisation.  The appearance of a flag does
not necessarily mean that resources were used incorrectly.  It depends upon the
tools being used and the contents of the SLURM header, and also depends upon
the job profile.  Because usage information is gathered every 5 minutes, higher
transient usage of cores or memory may not be captured in the log files.

Flags most likely to represent real overbooking of resources are
nodes_overbooked, overbooked, !!half_overbooked, !!severely_overbooked, and
!!swap_used.

For multinode jobs, flags other than nodes_overbooked are determined based only
on the usage of the first node.  Multinode jobs require careful analysis so as
to not waste resources unnecessarily, and it is a common mistake among
beginning Uppmax users to book multiple nodes and run tools that cannot use
more than the first.  In this case, nodes_overbooked will appear.

Some flags have a threshold below which they appear.  The default format is
generally 'flag:value-booked:value-used'.

  nodes_overbooked : nodes booked : nodes used
      More nodes were booked than used
  overbooked : % used (if < 80%)
      The maximum percentage of booked cores and/or memory that was used
  !!half_overbooked
      No more than 1/2 of both cores and memory of a node was used; consider booking 
      half a node instead.
  !!severely_overbooked
      No more than 1/4 of both cores and memory of a node was used, examine your job
      requirements closely.
  !!swap_used
      Swap storage was used at any point within the job run
  node_type_overbooked : type booked : type used
      A fat node was requested that was larger than was needed.  This flag may be
      produced spuriously if SLURM ran the job on a fat node when a fat node was not
      requested by the user.
  cores_overbooked : cores booked : cores used
      More cores were booked than used (if < 80%)
  mem_overbooked : GB booked : GB used
      More memory was available than was used (if < 25% and more than one core).
  core_mem_overbooked : GB in used cores : GB used
      Less memory was used than was available in the cores that were used (if < 50%).

By default no flags are indicated for jobs with memory-only cautions except for
swap usage, because it is common for jobs to heavily use processor cores
without using a sizable fraction of memory.  Use the -m/--memory option to
include flags for memory underutilisation when those would be the only flags
produced.

More verbose flags are output with the -v/--verbose option.


Script:   $0
Version:  $version

";

GetOptions("M=s"     => \$o_cluster, 
           "n=s"     => \$o_nodes,
           ""        => \$o_stdin,
           "stdin"   => \$o_stdin,
           "source"  => \$o_source,
           "memory"  => \$o_memory,
           "verbose" => \$o_verbose,
           "plot"    => \$o_plot,
           "d"       => \$o_header,
           "quiet"   => \$o_quiet,
           "x=s"     => \$o_prefix,
           "X=s"     => \$o_hardprefix,
           "f=s"     => \$o_finishedjobinfo,
           "r=s"     => \$o_plot_jobstats,
           "help|?"  => \$o_help) or die "$usage";
die "$usage$detailed_usage" if $o_help;

@jobs = @ARGV;

($o_cluster and ($o_stdin or scalar(@jobs) >= 1)) or die "\n***\n*** At least one jobid is required.\n***\n$usage";

$o_source = defined($source_values{$o_source}) ? $source_values{$o_source} : die "unrecognised --source value '$o_source'";

my $PREFIX = ( $o_hardprefix ? $o_hardprefix : "$o_prefix/$o_cluster/uppmax_jobstats" );

-d "$PREFIX" or die "\n***\n*** Jobstats directory prefix '$PREFIX/' is not a directory.\n***\n$usage";

my $username = scalar getpwuid $<;
my @user_groups = map { scalar getgrgid $_ } split ' ', $(;
my $in_staff = (scalar(grep /^staff$/, @user_groups) or ($username eq "root"));

my $jobcount = 0;
my $jobcount_notrun = 0;
my $no_jobstats_file = 0;

sub parseFinishedjobinfoLine($);
sub jobInfo($);
sub parseNodes($);
sub getJobstatsFiles($$@);
sub getJobstatsFileCoreCount($);
sub reorderNodeList($$);
sub runPlotJobstats(@);

# parse a single finishedjobinfo-formatted line and return a hash
sub parseFinishedjobinfoLine($) {
    my $line = shift;
    chomp $line;
    my (undef, undef, $keyvals) = split (/ /, $line, 3);
    return(0) if (! defined($keyvals));
    # note that null values "... nodes= ..." will result in no key in the hash
    my %h = $keyvals =~ /([^ ]+)=([^ ]+)/g;
    return(\%h);
}

# discover jobinfo for a single job using finishedjobinfo script
sub jobInfo($) {
    my $j = shift;
    -f "$o_finishedjobinfo" or die "\n***\n*** finishedjobinfo script '$o_finishedjobinfo' not available\n***";
    return parseFinishedjobinfoLine(qx($o_finishedjobinfo -q -M $o_cluster -j $j));
}

# parse list of nodes returned by finishedjobinfo or provided on -n
sub parseNodes($) {
    my $nds = shift;
    # nodes=                                # nodes=m80
    # nodes=m[26,74-75,77-78,81-84,88-89]   # nodes=m[100-101,103-104]
    # nodes=m[57,135-137]                   # nodes=m[135-136]
    # nodes=m2,m3,m4,m5
    # nonsensical results if finishedjobinfo-style and comma-separated are mixed
    if ($nds !~ /\[/) { # 0 or 1 nodes or comma-separated
        return ( $nds =~ /,/ ? split(/,/, $nds) : $nds ); 
    }
    $nds =~ s/^(.+)\[(.*)\]$/$2/g;  # strip off 'prefix'[ and ]
    my $node_prefix = $1;
    my @node_nums;
    foreach my $p ( split /,/, $nds ) {
        my @r = split /-/, $p;
        push @node_nums, ($#r ? ($r[0] .. $r[1]) : $r[0]);
    }
    return map { $node_prefix . $_ } @node_nums;
}

# find jobstats files, if they exist
sub getJobstatsFiles($$@) {  # cluster jobid node-list
    my $clstr = shift; 
    my $jbid = shift; 
    my @node_list = @_;
    # print STDERR "cluster:$clstr jobid:$jbid nodelist:", join(",", @node_list), "\n";
    my @file_list;
    foreach my $node ( @node_list ) {
        my $fn = ( $o_hardprefix ? "$PREFIX/$jbid" : "$PREFIX/$node/$jbid" );
        -f $fn and -s $fn and push @file_list, $fn;
    }
    return @file_list;
}

# look in jobstats file for number of cores used
sub getJobstatsFileCoreCount($) {
    my $file = shift;
    open(F, "<$file") or die "***\n*** Could not open jobstats file $file: $!\n***";
    scalar(<F>); # header line
    my $l = <F>; # first data line
    # first 5 fields are LOCALTIME, TIME, GB_LIMIT, GB_USED, GB_SWAP_USED
    my @f = split /[ \t]+/, $l;
    return scalar(@f) - 5;
}

# reorder node list putting nodes with jobstats files first
sub reorderNodeList($$) {
    my $nl = shift; my $fl = shift;
    my @old_node_list = @{$nl};
    my @file_list = @{$fl};
    my @new_node_list;
    my %seen;
    foreach my $file ( @file_list ) {
        my @p = split("/", $file);
        push @new_node_list, $p[-2];  # node name
        ++$seen{$p[-2]};
    }
    push @new_node_list, grep { $seen{$_} ? () : $_ } @old_node_list;
    return(@new_node_list);
}

sub runPlotJobstats(@) {
    my @args = @_;
    -f "$o_plot_jobstats" or die "\n***\n*** plot_jobstats.R script '$o_plot_jobstats' not available\n***";
    unshift @args, $source_R_flags{$o_source};  # --fji or --db, must be just before @_
    unshift @args, "--memory" if $o_memory;
    unshift @args, "--verbose" if $o_verbose;
    unshift @args, "--no-plot" if ! $o_plot;
    my $flags = qx($o_plot_jobstats @args);
    chomp $flags;
    return($flags);
}

sub print_JobNotRun($) {
    my $ji = shift;
    my @fields = ($ji->{jobid}, $o_cluster, $ji->{jobstate}, $ji->{username}, $ji->{account}, $ji->{jobname}, ".", $ji->{runtime}, "not_run", $ji->{procs}, ".", ".", ".");;
    print_JobRun(@fields);
}

my $header = "jobid\tcluster\tjobstate\tuser\tproject\tjobname\tendtime\truntime\tflag_list\tbooked\tcore_list\tnode_list\tjobstats_list";

sub print_JobRun(@) {
    my @fields = @_;
    if ($o_header and not $o_quiet) {  # don't print the header until ready to create output
        print STDOUT $header, "\n";
        $o_header = 0;
    }
    print STDOUT join("\t", @fields), "\n" if not $o_quiet;
    if ($fields[$#fields] eq ".") {
        ++$no_jobstats_file;
        # don't produce this warning for now, just rely on end-of-job summary
        if (0 and not $o_quiet) {
            print STDERR "*** No jobstats files found for jobid $fields[0], minimal resource usage diagnosis";
            print STDERR " and no plot can be produced" if $o_plot;
            print STDERR "\n";
        }
    }
}

@nodes = parseNodes($o_nodes) if $o_nodes;

while ( 1 ) {

    my $jobid;
    my $input_line;

    if ($o_stdin) {
        $input_line = <>;
        last if ! $input_line;
    } else {
        last if ! @jobs;
        $jobid = shift @jobs;
    }

    ++$jobcount;

    # $o_cluster already declared above
    my $jobstate = '.';
    my $user = '.';
    my $project = '.';
    my $jobname = '.';
    my $endtime = '.';
    my $runtime = '.';
    my $booked = '.';
    my $total_cores = 0;
    my @flag_list;
    my @core_list;
    my @node_list;
    my @file_list,
    my @jobstats_list;

    if (@nodes) {  # -n was used, use this list
        @node_list = @nodes;
    } else {  # discover using finishedjobinfo or stdin
        my $ji;
        if ($o_stdin) {
            $ji = parseFinishedjobinfoLine($input_line);
            die "***\n*** Jobid cannot be found, inconsistency in stdin input\n***" if ! $ji;
            $jobid = $ji->{jobid};
        } else {
            $ji = jobInfo($jobid);
            if (! $ji) {  # couldn't find jobinfo, give error and skip to next
                print STDERR "***\n*** Jobid $jobid cannot be found\n***\n";
                next;
            }
            if (! scalar(grep /^$ji->{account}$/, @user_groups) and ! $in_staff) {
                print STDERR "***\n*** Please, do not check other projects (jobid $jobid in $ji->{account})\n***\n";
                next;
            }
        }
        if (! defined($ji->{nodes})) {  # appears the job never started
            ++$jobcount_notrun;
            print_JobNotRun($ji);
            next;
        }
        @node_list = parseNodes($ji->{nodes});
        $jobstate = $ji->{jobstate};
        $user = $ji->{username};
        $project = $ji->{account}; 
        $jobname = $ji->{jobname};
        $endtime = $ji->{end_time};
        $runtime = $ji->{runtime};
        $booked = $ji->{procs};
    }
    @file_list = getJobstatsFiles($o_cluster, $jobid, @node_list);
    @node_list = reorderNodeList(\@node_list, \@file_list);
    foreach ( @file_list ) {
        my $cores = getJobstatsFileCoreCount($_);
        $total_cores += $cores;
        push @core_list, $cores;
    }

    # check flags that we can easily check here, overridden if there are R script results
    if (@file_list and @file_list < @node_list) {
        if ($o_verbose) {
            push @flag_list, scalar(@node_list) . " nodes booked but " . scalar(@file_list) . " used";
        } else {
            push @flag_list, "nodes_overbooked:" . scalar(@node_list) . ":" . scalar(@file_list);
        }
    }
    # do not include this flag, it is redundant and reporting simply nodes * cores-per-node
    if (0 and @file_list and $booked ne '.' and $total_cores < $booked) {
        if ($o_verbose) {
            push @flag_list, scalar(@node_list) . " total cores booked but " . scalar(@file_list) . " used";
        } else {
            push @flag_list, "cores_overbooked_all:" . $booked . ":" . $total_cores;
        }
    }
    # jobid cluster endtime runtime flag-list booked cores node-list jobstats-file-list
    my @fields;
    push @fields, $jobid;  # 0
    push @fields, $o_cluster; # 1
    push @fields, $jobstate; # 2
    push @fields, $user; # 3
    push @fields, $project; # 4
    push @fields, $jobname; # 5
    push @fields, $endtime; # 6
    push @fields, $runtime; # 7
    push @fields, (@flag_list ? join(",", @flag_list) : "."); my $flags_field = 8; # 8
    push @fields, $booked; # 9
    push @fields, (@core_list ? join(",", @core_list) : "."); # 10
    push @fields, join(",", @node_list); # 11
    push @fields, (@file_list ? join(",", @file_list) : "."); # 12

    # if we have files to read, run plot_jobstats.R script to check more flags and produce a plot
    if (@file_list) {
        my $pjs_flags = runPlotJobstats(@fields);
        $fields[$flags_field] = $pjs_flags if $pjs_flags;
    }

    print_JobRun(@fields);

}

if (not $o_quiet) {
    print STDERR "*** $jobcount total jobs, $jobcount_notrun jobs not run, $no_jobstats_file jobs had no jobstats files (includes jobs not run)\n";
}
if ($no_jobstats_file and $o_quiet) {
    print STDERR "*** No jobstats files found for $no_jobstats_file out of $jobcount jobs, limited resource usage diagnosis";
    print STDERR " and no plot produced" if $o_plot;
    print STDERR "\n";
}

