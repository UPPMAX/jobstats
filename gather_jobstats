#!/usr/bin/env perl

# DONE: (lka) help information about flag:number:number values
# DONE: (lka) verbose flag to be wordy about flag output?
# DONE: (lka) get current cluster from $SNIC_RESOURCE
# DONE: (lka) memory flag, perhaps only include if already a cores issue?
# DONE: perhaps include more about user, jobstate in plot and table?
# TODO: (lka) problem with plots from 100-node tintin job, and with 10-node tintin job
# TODO: add usage of Martin's sqlite3 db if it is available (i.e. if we are on milou-b)
# TODO: is there another, deeper, location for jobstats files we can check?

my $version = "2015-02-11";

use strict;
use warnings;
# use diagnostics;

use Getopt::Long qw(:config no_ignore_case);
use File::Basename;
use Cwd 'abs_path';

my $CWD = dirname(abs_path($0));
my $NAME = basename($0);

my $cluster = $ENV{'SNIC_RESOURCE'} ? $ENV{'SNIC_RESOURCE'} : 'milou';  # -M
my $source = "fji";  # -s/--source, "fji" for finishedjobinfo, "db" for Martin's database
my %source_values = ( fji => "fji", finishedjobinfo => "fji", db => "db" );
my %source_R_flags = ( fji => "--fji", db => "--db" );
my $do_plot = 0;         # -P
my $memory = 0;          # -m
my $nodes;               # -n
my @nodes;               # after unpacking finishedjobinfo or -n
my @jobs;                # user-specified jobids
my $help;                # -h
my $stdin = 0;           # -- which indicates accepting finishedjobinfo info on stdin
my $print_header = 0;    # -d
my $verbose = 0;         # -v
my $quiet = 0;           # -q
my $finishedjobinfo = "/sw/uppmax/bin/finishedjobinfo"; # -f
my $plot_jobstats_R = "$CWD/plot_jobstats.R"; # -r
my $prefix = "/sw/share/slurm"; # -x
my $hard_prefix = "";    # -X
my $usage = "
$NAME  [-h] [-p] [options] [ -M cluster ] [ -n node[,node...] ] [ jobid [ jobid ... ] | - ]

Discover jobstats for the specified job(s) on the specified cluster.

With the -p option, produce a plot for each jobid.  Plots contain one panel per
booked node showing CPU and memory usage, and include lines indicating the
usage flags.  Plots are saved to the current directory with the name
'cluster-jobid-project-user.png'.

Cluster defaults to the value of \$SNIC_RESOURCE ('$cluster' on the current system)
if not specified.

COMMAND-LINE OPTIONS
--------------------

    -M cluster         Cluster on which the job was run [default here is '$cluster']
    -n node[,node...]  Cluster node(s) on which the job was run.  If specified, then
                       the finishedjobinfo script is not run and discovery is
                       restricted to only the specified nodes.  Nodes can be specified
                       as a comma-separated list of complete node names, or using the
                       finishedjobinfo syntax:
                             m78,m90,m91,m92,m100  or  m[78,90-92,100]
                       Nonsensical results will occur if the syntaxes are mixed.
    - | --stdin        Accept input on stdin formatted like finishedjobinfo output.
                       The short form of this option is a single dash '-'.

    -m | --memory      Always include memory usage flags in output.  Default behaviour
                       is to include memory usage flags only if CPU usage flags are
                       also present.

    -s | --source fji | db
                       Source of the input data.  Default is '$source', the
                       finishedjobinfo script. 'db' may be used to access a more
                       rapid but less comprehensive database of job information.
                       This may also be used with the - flag when sending job
                       information via stdin.

    -v | --verbose     Be wordy when describing flag values.

    -p | --plot        Produce CPU and memory usage plot for each jobid

    -q | --quiet       Do not produce table output

    -d                 Produce a header for table output

    -h | --help | -?   Produce detailed help information

    jobid [jobid ...]  Job number valid on the cluster

The following command-line options are generally only useful for Uppmax staff.

    -x directory       Directory prefix to use for jobstats files.  Default is
                       '$prefix', and directory structure is 

                           <prefix>/<cluster>/uppmax_jobstats/<node>/<jobid>

    -X directory       Hard directory prefix to use for jobstats files.  Jobstats
                       files are assumed available directly: '<hard-prefix>/<jobid>'
    -f file            finishedjobinfo script [default is '$finishedjobinfo']
    -r file            plot_jobstats.R script [default is '$plot_jobstats_R']

";

my $detailed_usage = "DETAILED USAGE
--------------

There are three distinct modes for discovery about jobs of
interest.

  1. finishedjobinfo is used to discover information about jobs

         $NAME jobid1 jobid2 jobid3

  2. If the -n option is specified, then finishedjobinfo is not called and 
     jobstats files are sought directly for only the specified nodes

         $NAME -p -n m15,m16 jobid1
    
  3. Standard input is output from finishedjobinfo, which is then parsed for
     discovery.  Jobids examined are those present in the input.  This mode
     is enabled by using the - option and providing appropriate input on stdin,
     e.g.,

       finishedjobinfo project | grep 'jobstat=COMPLETED' | $NAME - -q -p
  
Note that not all jobs will produce jobstats files, particularly if the job was
cancelled or ran for less than 5 minutes.  Also, if a job booked nodes
inefficiently by not using nodes it asked for, jobstats files will not be
available for the booked but unused nodes.

OUTPUT
------

This script produces two types of output.  If the '-p' command line option is
provided, a plot is created of core and memory usage across the life
of the job.  The name of the file produced has the format:

    cluster-jobid-project-user.png

Also output for each job (unless the '-q' option is provided) is a
tab-separated line with the following fields:

  jobid cluster jobstate user project endtime runtime flags booked cores node[,node...] jobstats[,jobstats...] 

Field contents:

  jobid    : Job ID
  cluster  : Cluster on which the job was run
  jobstate : End status of the job: COMPLETED, FAILED, TIMEOUT, CANCELLED
  user     : Username that submitted the job
  project  : Project account under which the job was run
  endtime  : End time of the job (with -n, this is '.')
  runtime  : Runtime of the job (with -n, this is '.')
  flags    : Flags indicating various types of resource underutilizations
  booked   : Number of booked cores (with -n, this is '.')
  cores    : Number of cores represented in the discovered jobstats files.
  node     : Node(s) booked for the job, expanded into individual node names,
             separated by commas ','; if no nodes were found, this is '.'.  
             The nodes for which jobstats files are available are listed first.
  jobstats : jobstats files for the nodes, in the same order the nodes are 
             listed, separated by commas ','; if no jobstats files, this is '.'

FLAGS
-----

In both plot and table output, flags are a comma-separated list of cautions
regarding core and/or memory underutilisation.  The appearance of a flag does
not necessarily mean that resources were used incorrectly.  It depends upon the
tools being used and the contents of the SLURM header, and also depends upon
the job profile.  Because usage information is gathered every 5 minutes, higher
transient usage of cores or memory may not be captured in the log files.

Flags most likely to represent real overbooking of resources are nodes_overbooked,
overbooked, !!half_overbooked, !!severely_overbooked, and !!swap_used.

For multinode jobs, flags other than nodes_overbooked are determined based only
on the usage of the first node.  Multinode jobs require careful analysis so as
to not waste resources unnecessarily, and it is a common mistake among
beginning Uppmax users to book multiple nodes and run tools that cannot use
more than the first.  In this case, nodes_overbooked will appear.

Some flags have a threshold below which they appear.  The default format is
generally 'flag:value-booked:value-used'.

  nodes_overbooked : nodes booked : nodes used
      More nodes were booked than used
  overbooked : % used (if < 80%)
      The maximum percentage of booked cores and/or memory that was used
  !!half_overbooked
      No more than 1/2 of both cores and memory of a node was used; consider booking 
      half a node instead.
  !!severely_overbooked
      No more than 1/4 of both cores and memory of a node was used, examine your job
      requirements closely.
  !!swap_used
      Swap storage was used at any point within the job run
  node_type_overbooked : type booked : type used
      A fat node was requested that was larger than was needed.  This flag may be
      produced spuriously if SLURM ran the job on a fat node when a fat node was not
      requested by the user.
  cores_overbooked : cores booked : cores used
      More cores were booked than used (if < 80%)
  mem_overbooked : GB booked : GB used
      More memory was available than was used (if < 25% and more than one core).
  core_mem_overbooked : GB in used cores : GB used
      Less memory was used than was available in the cores that were used (if < 50%).

By default no flags are indicated for jobs with memory-only cautions except for
swap usage; use the -m option to include these flags on such jobs.  More
verbose flags are output with the -v option.

Script:   $0
Version:  $version

";

GetOptions("M=s"     => \$cluster, 
           "n=s"     => \$nodes,
           ""        => \$stdin,
           "stdin"   => \$stdin,
           "source"  => \$source,
           "memory"  => \$memory,
           "verbose" => \$verbose,
           "plot"    => \$do_plot,
           "d"       => \$print_header,
           "quiet"   => \$quiet,
           "x=s"     => \$prefix,
           "X=s"     => \$hard_prefix,
           "f=s"     => \$finishedjobinfo,
           "r=s"     => \$plot_jobstats_R,
           "help|?"  => \$help) or die "$usage";
die "$usage$detailed_usage" if $help;

@jobs = @ARGV;

($cluster and ($stdin or scalar(@jobs) >= 1)) or die "\n***\n*** At least one jobid is required.\n***\n$usage";

$source = defined($source_values{$source}) ? $source_values{$source} : die "unrecognised --source value '$source'";

my $PREFIX = ( $hard_prefix ? $hard_prefix : "$prefix/$cluster/uppmax_jobstats" );

-d "$PREFIX" or die "\n***\n*** Jobstats directory prefix '$PREFIX/' is not a directory.\n***\n$usage";

my $username = scalar getpwuid $<;
my @user_groups = map { scalar getgrgid $_ } split ' ', $(;
my $in_staff = (scalar(grep /^staff$/, @user_groups) or ($username eq "root"));

my $jobcount = 0;
my $jobcount_notrun = 0;
my $no_jobstats_file = 0;

sub parseFinishedjobinfoLine($);
sub jobInfo($);
sub parseNodes($);
sub getJobstatsFiles($$@);
sub getJobstatsFileCoreCount($);
sub reorderNodeList($$);
sub runPlotJobstats(@);

# parse a single finishedjobinfo-formatted line and return a hash
sub parseFinishedjobinfoLine($) {
    my $line = shift;
    chomp $line;
    my (undef, undef, $keyvals) = split (/ /, $line, 3);
    return(0) if (! defined($keyvals));
    # note that null values "... nodes= ..." will result in no key in the hash
    my %h = $keyvals =~ /([^ ]+)=([^ ]+)/g;
    return(\%h);
}

# discover jobinfo for a single job using finishedjobinfo script
sub jobInfo($) {
    my $j = shift;
    -f "$finishedjobinfo" or die "\n***\n*** finishedjobinfo script '$finishedjobinfo' not available\n***";
    return parseFinishedjobinfoLine(qx($finishedjobinfo -q -M $cluster -j $j));
}

# parse list of nodes returned by finishedjobinfo or provided on -n
sub parseNodes($) {
    my $nodes = shift;
    # nodes=                                # nodes=m80
    # nodes=m[26,74-75,77-78,81-84,88-89]   # nodes=m[100-101,103-104]
    # nodes=m[57,135-137]                   # nodes=m[135-136]
    # nodes=m2,m3,m4,m5
    # nonsensical results if finishedjobinfo-style and comma-separated are mixed
    if ($nodes !~ /\[/) { # 0 or 1 nodes or comma-separated
        return ( $nodes =~ /,/ ? split(/,/, $nodes) : $nodes ); 
    }
    $nodes =~ s/^(.+)\[(.*)\]$/$2/g;  # strip off 'prefix'[ and ]
    my $node_prefix = $1;
    my @node_nums;
    foreach my $p ( split /,/, $nodes ) {
        my @r = split /-/, $p;
        push @node_nums, ($#r ? ($r[0] .. $r[1]) : $r[0]);
    }
    return map { $node_prefix . $_ } @node_nums;
}

# find jobstats files, if they exist
sub getJobstatsFiles($$@) {  # cluster jobid node-list
    my $cluster = shift; 
    my $jobid = shift; 
    my @node_list = @_;
    # print STDERR "cluster:$cluster jobid:$jobid nodelist:", join(",", @node_list), "\n";
    my @file_list;
    foreach my $node ( @node_list ) {
        my $fn = ( $hard_prefix ? "$PREFIX/$jobid" : "$PREFIX/$node/$jobid" );
        -f $fn and -s $fn and push @file_list, $fn;
    }
    return @file_list;
}

# look in jobstats file for number of cores used
sub getJobstatsFileCoreCount($) {
    my $file = shift;
    open(F, "<$file") or die "***\n*** Could not open jobstats file $file: $!\n***";
    scalar(<F>); # header line
    my $l = <F>; # first data line
    # first 5 fields are LOCALTIME, TIME, GB_LIMIT, GB_USED, GB_SWAP_USED
    my @f = split /[ \t]+/, $l;
    return scalar(@f) - 5;
}

# reorder node list putting nodes with jobstats files first
sub reorderNodeList($$) {
    my $nl = shift; my $fl = shift;
    my @old_node_list = @{$nl};
    my @file_list = @{$fl};
    my @new_node_list;
    my %seen;
    foreach my $file ( @file_list ) {
        my @p = split("/", $file);
        push @new_node_list, $p[-2];  # node name
        ++$seen{$p[-2]};
    }
    push @new_node_list, grep { $seen{$_} ? () : $_ } @old_node_list;
    return(@new_node_list);
}

sub runPlotJobstats(@) {
    my @args = @_;
    -f "$plot_jobstats_R" or die "\n***\n*** plot_jobstats.R script '$plot_jobstats_R' not available\n***";
    unshift @args, $source_R_flags{$source};  # --fji or --db, must be just before @_
    unshift @args, "--memory" if $memory;
    unshift @args, "--verbose" if $verbose;
    unshift @args, "--no-plot" if ! $do_plot;
    my $flags = qx($plot_jobstats_R @args);
    chomp $flags;
    return($flags);
}

sub print_JobNotRun($) {
    my $ji = shift;
    my @fields = ($ji->{jobid}, $cluster, $ji->{jobstate}, $ji->{username}, $ji->{account}, $ji->{jobname}, ".", $ji->{runtime}, "not_run", $ji->{procs}, ".", ".", ".");;
    print_JobRun(@fields);
}

my $header = "jobid\tcluster\tjobstate\tuser\tproject\tjobname\tendtime\truntime\tflag_list\tbooked\tcore_list\tnode_list\tjobstats_list";

sub print_JobRun(@) {
    my @fields = @_;
    if ($print_header and not $quiet) {  # don't print the header until ready to create output
        print STDOUT $header, "\n";
        $print_header = 0;
    }
    print STDOUT join("\t", @fields), "\n" if not $quiet;
    if ($fields[$#fields] eq ".") {
        ++$no_jobstats_file;
        # don't produce this warning for now, just rely on end-of-job summary
        if (0 and not $quiet) {
            print STDERR "*** No jobstats files found for jobid $fields[0], minimal resource usage diagnosis";
            print STDERR " and no plot can be produced" if $do_plot;
            print STDERR "\n";
        }
    }
}

@nodes = parseNodes($nodes) if $nodes;

while ( 1 ) {

    my $jobid;
    my $input_line;

    if ($stdin) {
        $input_line = <>;
        last if ! $input_line;
    } else {
        last if ! @jobs;
        $jobid = shift @jobs;
    }

    ++$jobcount;

    # $cluster already declared above
    my $jobstate = '.';
    my $user = '.';
    my $project = '.';
    my $jobname = '.';
    my $endtime = '.';
    my $runtime = '.';
    my $booked = '.';
    my $total_cores = 0;
    my @flag_list;
    my @core_list;
    my @node_list;
    my @file_list,
    my @jobstats_list;

    if (@nodes) {  # -n was used, use this list
        @node_list = @nodes;
    } else {  # discover using finishedjobinfo or stdin
        my $ji;
        if ($stdin) {
            $ji = parseFinishedjobinfoLine($input_line);
            die "***\n*** Jobid cannot be found, inconsistency in stdin input\n***" if ! $ji;
            $jobid = $ji->{jobid};
        } else {
            $ji = jobInfo($jobid);
            if (! $ji) {  # couldn't find jobinfo, give error and skip to next
                print STDERR "***\n*** Jobid $jobid cannot be found\n***\n";
                next;
            }
            if (! scalar(grep /^$ji->{account}$/, @user_groups) and ! $in_staff) {
                print STDERR "***\n*** Please, do not check other projects (jobid $jobid in $ji->{account})\n***\n";
                next;
            }
        }
        if (! defined($ji->{nodes})) {  # appears the job never started
            ++$jobcount_notrun;
            print_JobNotRun($ji);
            next;
        }
        @node_list = parseNodes($ji->{nodes});
        $jobstate = $ji->{jobstate};
        $user = $ji->{username};
        $project = $ji->{account}; 
        $jobname = $ji->{jobname};
        $endtime = $ji->{end_time};
        $runtime = $ji->{runtime};
        $booked = $ji->{procs};
    }
    @file_list = getJobstatsFiles($cluster, $jobid, @node_list);
    @node_list = reorderNodeList(\@node_list, \@file_list);
    foreach ( @file_list ) {
        my $cores = getJobstatsFileCoreCount($_);
        $total_cores += $cores;
        push @core_list, $cores;
    }

    # check flags that we can easily check here, overridden if there are R script results
    if (@file_list and @file_list < @node_list) {
        if ($verbose) {
            push @flag_list, scalar(@node_list) . " nodes booked but " . scalar(@file_list) . " used";
        } else {
            push @flag_list, "nodes_overbooked:" . scalar(@node_list) . ":" . scalar(@file_list);
        }
    }
    # do not include this flag, it is redundant and reporting simply nodes * cores-per-node
    if (0 and @file_list and $booked ne '.' and $total_cores < $booked) {
        if ($verbose) {
            push @flag_list, scalar(@node_list) . " total cores booked but " . scalar(@file_list) . " used";
        } else {
            push @flag_list, "cores_overbooked_all:" . $booked . ":" . $total_cores;
        }
    }
    # jobid cluster endtime runtime flag-list booked cores node-list jobstats-file-list
    my @fields;
    push @fields, $jobid;  # 0
    push @fields, $cluster; # 1
    push @fields, $jobstate; # 2
    push @fields, $user; # 3
    push @fields, $project; # 4
    push @fields, $jobname; # 5
    push @fields, $endtime; # 6
    push @fields, $runtime; # 7
    push @fields, (@flag_list ? join(",", @flag_list) : "."); my $flags_field = 8; # 8
    push @fields, $booked; # 9
    push @fields, (@core_list ? join(",", @core_list) : "."); # 10
    push @fields, join(",", @node_list); # 11
    push @fields, (@file_list ? join(",", @file_list) : "."); # 12

    # if we have files to read, run plot_jobstats.R script to check more flags and produce a plot
    if (@file_list) {
        my $pjs_flags = runPlotJobstats(@fields);
        $fields[$flags_field] = $pjs_flags if $pjs_flags;
    }

    print_JobRun(@fields);

}

if (not $quiet) {
    print STDERR "*** $jobcount total jobs, $jobcount_notrun jobs not run, $no_jobstats_file jobs had no jobstats files (includes jobs not run)\n";
}
if ($no_jobstats_file and $quiet) {
    print STDERR "*** No jobstats files found for $no_jobstats_file out of $jobcount jobs, limited resource usage diagnosis";
    print STDERR " and no plot produced" if $do_plot;
    print STDERR "\n";
}

